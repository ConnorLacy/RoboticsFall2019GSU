{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Human Faces\n",
    "\n",
    "Before anything else, a PiCamera has to be connected to the Raspberry Pi.\n",
    "\n",
    "In this notebook, we are using pre-trained Haar-Cascade classifiers for human faces and eyes. These pretrained classifiers which come with `opencv` are stored in an XML format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import picamera\n",
    "from picamera import PiCamera\n",
    "import matplotlib.pyplot as plt\n",
    "from picamera.array import PiRGBArray\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import IPython\n",
    "import io\n",
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are reading a continuous stream of RGB photos taken from the video port, we also need to display them continuously. For this matter we need the following function to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 'jpeg' instead of 'png' (~5 times faster)\n",
    "def showarray(a, fmt='jpeg'):\n",
    "    '''\n",
    "    Function to display an image within a Jupyter notebook.\n",
    "    '''\n",
    "    im_array = np.asarray(a)\n",
    "    plt.imshow(im_array)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load up the classifiers for eyes and faces. These 2 files should be located in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_cascade = cv.CascadeClassifier('haarcascade_upperbody.xml')\n",
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "eye_cascade = cv.CascadeClassifier('haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is used to detect the human faces and eyes. `detectMultiScale` returns a list of coordinates where it detected something and if there's something, then it proceeds drawing green and red rectangles around the detected features. The image that now contains these red/green boxes is returned to where it got called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectFacesAndEyes(img_array):\n",
    "    '''\n",
    "    Function to detect eyes and faces using a Haar-Cascade classifier.\n",
    "    '''\n",
    "    gray = cv.cvtColor(img_array, cv.COLOR_BGR2GRAY)\n",
    "    body = body = body_cascade.detectMultiScale(gray,scaleFactor = 1.01,minNeighbors = 5,flags = cv.CASCADE_SCALE_IMAGE)\n",
    "    for (x,y,w,h) in body:\n",
    "        cv.rectangle(img_array,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img_array[y:y+h, x:x+w]\n",
    "        faces = face_cascade.detectMultiScale(roi_gray)\n",
    "        for (fx,fy,fw,fh) in faces:\n",
    "            cv.rectangle(roi_color,(fx,fy),(fx+fw,fy+fh),(0,255,0),2)\n",
    "            roi_gray_face = roi_gray[y:y+h, x:x+w]\n",
    "            roi_color_face = roi_color[y:y+h, x:x+w]\n",
    "            eyes = eye_cascade.detectMultiScale(roi_gray_face)\n",
    "            for (ex,ey,ew,eh) in eyes:\n",
    "                cv.rectangle(roi_color_face,(ex,ey),(ex+ew,ey+eh),(255,0,0),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capture frames at the highest rate possible and on each frame run the Haar-Cascade detection system.\n",
    "\n",
    "Finally, on each iteration, the image gets to be displayed in JupyterLab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "PiCameraMMALError",
     "evalue": "Failed to enable connection: Out of resources",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPiCameraMMALError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-17832794f058>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# initialize the camera and grab a reference to the raw camera capture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcamera\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPiCamera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpicamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvflip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframerate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/picamera/camera.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, camera_num, stereo_mode, stereo_decimate, resolution, framerate, sensor_mode, led_pin, clock_mode, framerate_range)\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_camera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcamera_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstereo_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstereo_decimate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure_camera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensor_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframerate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclock_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_preview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_splitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_camera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/picamera/camera.py\u001b[0m in \u001b[0;36m_init_preview\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;31m# fade to black (issue #22)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         self._preview = PiNullSink(\n\u001b[0;32m--> 513\u001b[0;31m             self, self._camera.outputs[self.CAMERA_PREVIEW_PORT])\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_start_capture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/picamera/renderers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parent, source)\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMMALNullSink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/picamera/mmalobj.py\u001b[0m in \u001b[0;36menable\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2210\u001b[0m         mmal_check(\n\u001b[1;32m   2211\u001b[0m             \u001b[0mmmal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmmal_connection_enable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2212\u001b[0;31m             prefix=\"Failed to enable connection\")\n\u001b[0m\u001b[1;32m   2213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m             \u001b[0mMMALPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_all_buffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/picamera/exc.py\u001b[0m in \u001b[0;36mmmal_check\u001b[0;34m(status, prefix)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \"\"\"\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmmal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMMAL_SUCCESS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mPiCameraMMALError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPiCameraMMALError\u001b[0m: Failed to enable connection: Out of resources"
     ]
    }
   ],
   "source": [
    "# initialize the camera and grab a reference to the raw camera capture\n",
    "camera = PiCamera()\n",
    "camera.resolution = (320,240)\n",
    "picamera.camera.vflip = True\n",
    "camera.framerate = 32\n",
    "freshest_frame = PiRGBArray(camera, size=(320,240))\n",
    "\n",
    "# allow the camera to warmup\n",
    "time.sleep(0.1)\n",
    "\n",
    "\n",
    "for frame in camera.capture_continuous(freshest_frame, format=\"rgb\", use_video_port=True):\n",
    "            img = frame.array\n",
    "            \n",
    "            detectFacesAndEyes(img)\n",
    "            \n",
    "            showarray(img)\n",
    "            IPython.display.clear_output(wait = True)\n",
    "            #cv.imshow(\"frame\",img)\n",
    "            #key = cv.waitKey(1) & 0xFF\n",
    "            \n",
    "            # clear the stream in preparation for the next frame\n",
    "            freshest_frame.truncate(0)\n",
    "            \n",
    "            # if the `q` key was pressed, break from the loop\n",
    "            #if key == ord(\"q\"):\n",
    "            #    break\n",
    "                \n",
    "            #showarray(freshest_frame)\n",
    "            #IPython.display.clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
